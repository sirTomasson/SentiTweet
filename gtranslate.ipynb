{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edbbe05a-a208-400c-b6d5-b684e9f48b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠INFO    🕑01/08/2022 07:10:31 AM root Core count: 8.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import random\n",
    "import multiprocessing\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from time import perf_counter\n",
    "from logging import info, error, warning, debug\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import wait\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s 🕑%(asctime)s %(name)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "                    stream=sys.stdout, \n",
    "                    level=logging.INFO)\n",
    "\n",
    "logging.addLevelName(logging.DEBUG,   \"🤓DEBUG  \")\n",
    "logging.addLevelName(logging.INFO,    \"🧠INFO   \")\n",
    "logging.addLevelName(logging.WARNING, \"🤒WARNING\")\n",
    "logging.addLevelName(logging.ERROR,   \"💣ERROR  \")\n",
    "\n",
    "info(f\"Core count: {multiprocessing.cpu_count()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7b32c00-58ee-4229-a6f8-c88f01600857",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://translate.google.com/m\"\n",
    "\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:95.0) Gecko/20100101 Firefox/95.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.54 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36\"\n",
    "]\n",
    "\n",
    "\n",
    "def get_random_useragent():\n",
    "    \"\"\"\n",
    "    This function returns a random user agent from the user_agents list.\n",
    "    @return: a user agent from the user_agents list.\n",
    "    \"\"\"\n",
    "    index = random.randint(0, len(user_agents)-1)\n",
    "    user_agent = user_agents[index]\n",
    "    return user_agent\n",
    "\n",
    "\n",
    "def gtranslate(text):\n",
    "    \"\"\"\n",
    "    This function translates a text using the Google translate API.\n",
    "    \"\"\"\n",
    "    user_agent = get_random_useragent()\n",
    "    response = requests.get(base_url,\n",
    "                            params={\"q\": text},\n",
    "                            headers={\"user-agent\": user_agent})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 429:\n",
    "            error(f\"To many requests {response.status_code}.\")\n",
    "            info(\"Script encountered status 429: to requests. Waitin for 30 minutes to resume\")\n",
    "            time.sleep(1800)\n",
    "            info(\"Script resumes after 30 minutes\")\n",
    "            return gtranslate(text)\n",
    "        else:\n",
    "            error(f\"Received status: {response.status_code}.\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    element = soup.find(\"div\", {\"class\": \"t0\"})\n",
    "\n",
    "    if not element:\n",
    "        element = soup.find(\"div\", {\"class\": \"result-container\"})\n",
    "\n",
    "    translated = None\n",
    "    if element:\n",
    "        translated = element.get_text()\n",
    "    return translated\n",
    "\n",
    "\n",
    "def batch_gtranslate(texts):\n",
    "    \"\"\"\n",
    "    This function runs gtranslate in batch mode.\n",
    "\n",
    "    @param: texts: list of texts that need to be translated\n",
    "    @return: list of translated texts.\n",
    "    \"\"\"\n",
    "    translated_texts = []\n",
    "    start = perf_counter()\n",
    "    for text in texts:\n",
    "        translated_text = gtranslate(text)\n",
    "        translated_texts.append(translated_text)\n",
    "\n",
    "    elapsed_time = perf_counter()-start\n",
    "    debug(f\"batch_translate: text_count: {len(texts)}, took: {elapsed_time:.2f} seconds.\")\n",
    "    return translated_texts\n",
    "\n",
    "def batch_gtranslate_df(df):\n",
    "    return df[\"full_text\"].apply(lambda txt: gtranslate(txt))\n",
    "\n",
    "\n",
    "def para_gtranslate(texts, min_batch_size=6, batch_count=None):\n",
    "    \"\"\"\n",
    "    This function batch translates texts in parallel.\n",
    "\n",
    "    @param: texts: list of texts to translate\n",
    "    @param: batch_size: batch size of texts processed per thread. Default is 6.\n",
    "    \"\"\"\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    if batch_count is None:\n",
    "        thread_count = cpu_count*2\n",
    "    else:\n",
    "        thread_count = batch_count\n",
    "    info(f\"Running parallel gtranslate with cpu count: {cpu_count}, and threads: {thread_count} available.\")\n",
    "    batch_size = min_batch_size\n",
    "    if len(texts)/thread_count <= min_batch_size:\n",
    "        # Number of threads is greater then number of texts to translate\n",
    "        # Example 32 threads and 14 texts, then three threads will spawned.\n",
    "        # Two threads will processes 6 texts and 1 will processes 2 texts.\n",
    "        batch_count = math.ceil(len(texts)/batch_size)\n",
    "\n",
    "    else:\n",
    "        # Texts is greater then number threads.\n",
    "        # Example: 256 texts and 32 threads, each thread will processes \n",
    "        # 8 texts.\n",
    "        batch_size = math.ceil(len(texts)/thread_count)\n",
    "        batch_count = thread_count\n",
    "\n",
    "    info(f\"Start translation with batch_count: {batch_count}, batch_size: {batch_size}.\")\n",
    "    result = []\n",
    "    futures = []\n",
    "    with ThreadPoolExecutor(batch_count) as executor:\n",
    "        for i in range(0, batch_count):\n",
    "            start = i*batch_size\n",
    "            end = start+batch_size\n",
    "            if end > len(texts):\n",
    "                end = len(texts)\n",
    "            batch = texts[start:end:]\n",
    "            future = executor.submit(batch_gtranslate, batch)\n",
    "            futures.append(future)\n",
    "\n",
    "    wait(futures)\n",
    "    for future in futures:\n",
    "        translated_texts = future.result()\n",
    "        for text in translated_texts:\n",
    "            result.append(text)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def translate_column(df, column_name):\n",
    "    \"\"\"\n",
    "    This function translates a hydrated data-set.\n",
    "\n",
    "    @param: df: this is a pandas dataframe.\n",
    "    @param: column_name: name of the column inside the dataframe that needs to be translated. \n",
    "    @return: dataframe containing a new column called 'processed_text'\n",
    "    \"\"\"\n",
    "    texts = df[column_name].tolist()\n",
    "\n",
    "    translated_texts = para_gtranslate(texts)\n",
    "\n",
    "    se = pd.Series(translated_texts)\n",
    "\n",
    "    df[\"processed_texts\"] = se.values\n",
    "    return df\n",
    "\n",
    "\n",
    "def translate_dataset(dirpath, overwrite_cache=True):\n",
    "    \"\"\"\n",
    "    This function translates a dataset of hydrated tweets.\n",
    "    A dataset is considered a directory containing .csv files.\n",
    "    Each files is read into a pandas dataframe and then written to \n",
    "    directory called 'processed'. The processed directory is a sibling \n",
    "    of the hydrated directory.\n",
    "\n",
    "    This function caches results so if file hydrated/A.csv and processed/A.csv\n",
    "    exists then A.csv is skipped. Moreover if a the file 'B.csv' exists in the \n",
    "    hydrated directory but not in the processed directory the file is translated \n",
    "    and written to the processed directory.\n",
    "\n",
    "    @param: dirpath: The path to the dataset. The dataset must be a directory.\n",
    "    @param: overwrite_cache: Whether caching is enabled. The default value is True\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dirpath) and not os.path.isdir(dirpath):\n",
    "        raise FileNotFoundError(\"File 'dirpath' does not exist or is not a directory.\")\n",
    "\n",
    "    parentdir = os.path.dirname(dirpath)\n",
    "    # create a path to directory that is a sibling of 'dirpath' variable.\n",
    "    processeddir = os.path.join(parentdir, \"processed\")\n",
    "    # create a directory called 'processed' for the processed dataset if it does not yet exist.\n",
    "    if not os.path.exists(processeddir):\n",
    "        os.mkdir(processeddir)\n",
    "        info(f\"Created directory: {processeddir}.\")\n",
    "\n",
    "    filenames = [file for file in os.listdir(dirpath) if file.endswith(\".csv\")]\n",
    "    for file in filenames:\n",
    "        filepath = os.path.join(dirpath, file)\n",
    "        processed_filepath = os.path.join(processeddir, file)\n",
    "        if not overwrite_cache and os.path.exists(processed_filepath):\n",
    "            info(f\"File already exists in: {processed_filepath}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(filepath,\n",
    "                         index_col=\"id\",\n",
    "                         usecols=[\"id\", \"full_text\", \"created_at\"],\n",
    "                         dtype={\"id\": \"int64\"},\n",
    "                         parse_dates=[\"created_at\"])\n",
    "        df = ratelimit_gtranslate(df,\n",
    "                                  rate_limit=5000,\n",
    "                                  lowerbound_wait=1800,\n",
    "                                  upperbound_wait=2700)\n",
    "        df.to_csv(processed_filepath)\n",
    "        info(f\"Created new processed file in: {processed_filepath}.\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def read_hydrated_csv(filename):\n",
    "    df = pd.read_csv(filename,\n",
    "                     index_col=\"id\",\n",
    "                     usecols=[\"id\", \"full_text\", \"created_at\"],\n",
    "                     dtype={\"id\": \"int64\"},\n",
    "                     parse_dates=[\"created_at\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def ratelimit_gtranslate(df,\n",
    "                         rate_limit=20000,\n",
    "                         lowerbound_wait=900,\n",
    "                         upperbound_wait=2700):\n",
    "    \"\"\"\n",
    "    Rate limited translate function. Translates a hydrated Dataframe with a\n",
    "    certain rate limit in mind. Once the limit is reached the script\n",
    "    waits for a certain amount of time before continueing; between\n",
    "    lowerbound_wait and upperbound_wait.\\n\\n\n",
    "    @param: df: Dataframe of a hydrated dataset; it is assumed it contains\n",
    "                column: full_text\\n.\n",
    "    @param: rate_limit: the amount of rows that are processed before the wait\n",
    "                        time kicks-in.\n",
    "    @param: lowerbound_wait: minimum wait time in seconds;\n",
    "                             default lowerbound_wait=900.\n",
    "    @param: upperbound_wait: maximum wait time in seconds;\n",
    "                             default lowerbound_wait=2700.\n",
    "    @return: Dataframe containing a new column named 'processed_text'.\n",
    "    \"\"\"\n",
    "    batch_count = math.ceil(len(df)/rate_limit)\n",
    "\n",
    "    result_df = None\n",
    "\n",
    "    request_count = 0\n",
    "\n",
    "    for i in range(0, batch_count):\n",
    "        start = i*rate_limit\n",
    "        end = start+rate_limit\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "\n",
    "        batch = df.iloc[start:end]\n",
    "        texts = batch.full_text.values\n",
    "\n",
    "        if result_df is None:\n",
    "            translated_texts = para_gtranslate(texts)\n",
    "            batch.loc[:, [\"processed_text\"]] = translated_texts\n",
    "            result_df = batch\n",
    "        else:\n",
    "            translated_texts = para_gtranslate(texts)\n",
    "            batch.loc[:, [\"processed_text\"]] = translated_texts\n",
    "            result_df = result_df.append(batch)\n",
    "\n",
    "        request_count = request_count+len(batch)\n",
    "\n",
    "        if request_count >= rate_limit:\n",
    "            wait_time = random.randint(lowerbound_wait, upperbound_wait)\n",
    "            info(f\"\"\"Rate limit exceeded, current request count is\n",
    "            {request_count}; Sleep for {wait_time} seconds.\"\"\")\n",
    "            time.sleep(wait_time)\n",
    "            info(f\"Script resumes after {wait_time} seconds of sleep.\")\n",
    "            request_count = 0\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b676d49c-c5b1-41ea-98f1-49dab8fc8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gtranslate():\n",
    "    text = \"Liever te dik in de kist dan een feestje gemist.\"\n",
    "    gtranslate(text)\n",
    "\n",
    "\n",
    "def test_batch_gtranslate():\n",
    "    texts = [\n",
    "        \"Liever te dik in de kist dan een feestje gemist.\",\n",
    "        \"Hallo welt\",\n",
    "        \"Buenos dias\"\n",
    "    ]\n",
    "    batch_gtranslate(texts)\n",
    "\n",
    "\n",
    "def test_para_gtranslate():\n",
    "    texts = [\n",
    "        \"Liever te dik in de kist dan een feestje gemist.\",\n",
    "        \"Hallo welt\",\n",
    "        \"Buenos dias\"\n",
    "    ]\n",
    "    result = para_gtranslate(texts, min_batch_size=2)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "360a3c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Type\n"
     ]
    }
   ],
   "source": [
    "def type_check(correct_type):\n",
    "    def check(old_function):\n",
    "        def new_function(arg):\n",
    "            if (isinstance(arg, correct_type)):\n",
    "                return old_function(arg)\n",
    "            else:\n",
    "                print(\"Bad Type\")\n",
    "        return new_function\n",
    "    return check\n",
    "\n",
    "\n",
    "        \n",
    "@type_check(int)\n",
    "def times2(num):\n",
    "    return num*2\n",
    "\n",
    "num = \"2\"\n",
    "\n",
    "times2(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52dc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(input_path, chunksize=1000, limit=-1, n=8):\n",
    "    info(f\"translate_file: params:[input_path={input_path}, chunksize={chunksize}, limit={limit}, n={n}].\")\n",
    "    \n",
    "    hydrated_path = os.path.dirname(input_path)\n",
    "    dataset_path = os.path.dirname(hydrated_path)\n",
    "    processed_path = os.path.join(dataset_path, \"processed\")\n",
    "    filename = input_path.split(os.path.sep)\n",
    "    filename = filename[len(filename)-1]\n",
    "    result_path = os.path.join(processed_path, filename)\n",
    "\n",
    "    count=0\n",
    "    batch_size=math.ceil(chunksize/n)\n",
    "    thread_count=min(n,batch_size)\n",
    "\n",
    "    df2 = None\n",
    "    if os.path.exists(result_path):\n",
    "        info(f\"translate_file: found {result_path}!\")\n",
    "        df2 = pd.read_csv(result_path, \n",
    "              index_col=\"id\",\n",
    "              usecols=[\"id\", \"full_text\", \"created_at\"])\n",
    "\n",
    "    for df in pd.read_csv(input_path, \n",
    "                          chunksize=chunksize,\n",
    "                          index_col=\"id\",\n",
    "                          usecols=[\"id\", \"full_text\", \"created_at\"]):\n",
    "        if df2 is not None:\n",
    "            df = df[~df.index.isin(df2.index)]\n",
    "            if len(df) == 0:\n",
    "                info(f\"translate_file: no diff in current chunk; files: [{input_path} {result_path}; skipping!]\")\n",
    "                continue\n",
    "            else:\n",
    "                info(f\"translate_file: diff size is {len(df)} for current chunk; filenames: [{input_path} {result_path}!]\")\n",
    "        \n",
    "        batches = [df[i:i+batch_size] for i in range(0, len(df),batch_size)]\n",
    "        result = None\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor(n) as executor:\n",
    "            for batch in batches:\n",
    "                future = executor.submit(batch_gtranslate_df, batch)\n",
    "                futures.append(future)\n",
    "\n",
    "        wait(futures)\n",
    "        for future in futures:\n",
    "            translated_batch = future.result()\n",
    "            if result is None:\n",
    "                result = translated_batch\n",
    "            else:\n",
    "                result = result.append(translated_batch)\n",
    "\n",
    "        df[\"processed_text\"] = result\n",
    "        if not os.path.exists(result_path):\n",
    "            df.to_csv(result_path)\n",
    "            info(f\"translate_file:📝created new file at {result_path}.\")\n",
    "        else:\n",
    "            df.to_csv(result_path, mode=\"a\", header=False)\n",
    "            info(f\"translate_file:📝appended {len(df)} rows to {result_path}.\")\n",
    "        count = count + len(df)\n",
    "        if limit != -1 and count >= limit:\n",
    "            info(f\"translate_file: limit reached, limit={limit} and count={count};👋exiting!\")\n",
    "            break\n",
    "    \n",
    "\n",
    "def translate_dataset2(path):\n",
    "    csv_paths = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    info(f\"translate_dataset2: translating files: {csv_paths}, from {path}.\")\n",
    "    for cvs_path in csv_paths:\n",
    "        translate_file(cvs_path, limit=2000, n=4)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08d37ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_dataset2: translating files: ['data-sets/Lopez1/hydrated/output2020_05.csv', 'data-sets/Lopez1/hydrated/output2020_03.csv'], from data-sets/Lopez1/hydrated.\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: params:[input_path=data-sets/Lopez1/hydrated/output2020_05.csv, chunksize=1000, limit=2000, n=4].\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: found data-sets/Lopez1/processed/output2020_05.csv!\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: no diff in current chunk; files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/08/2022 07:12:49 AM root translate_file: diff size is 1000 for current chunk; filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/08/2022 07:13:37 AM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/08/2022 07:13:37 AM root translate_file: diff size is 1000 for current chunk; filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/08/2022 07:14:25 AM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/08/2022 07:14:25 AM root translate_file: limit reached, limit=2000 and count=2000;👋exiting!\n",
      "🧠INFO    🕑01/08/2022 07:14:25 AM root translate_file: params:[input_path=data-sets/Lopez1/hydrated/output2020_03.csv, chunksize=1000, limit=2000, n=4].\n",
      "🧠INFO    🕑01/08/2022 07:15:14 AM root translate_file:📝created new file at data-sets/Lopez1/processed/output2020_03.csv.\n",
      "🧠INFO    🕑01/08/2022 07:16:00 AM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_03.csv.\n",
      "🧠INFO    🕑01/08/2022 07:16:00 AM root translate_file: limit reached, limit=2000 and count=2000;👋exiting!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"data-sets\", \"Lopez1\")\n",
    "hydrated_path = os.path.join(dataset_path, \"hydrated\")\n",
    "\n",
    "translate_dataset2(hydrated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db0fcc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: params:[filename=output2020_05.csv, chunksize=1000, limit=5000, n=8].\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: found data-sets/Lopez1/processed/output2020_05.csv!\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: no diff in current chunk for files: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv; skipping!]\n",
      "🧠INFO    🕑01/07/2022 03:55:29 PM root translate_file: diff size is 1000 for current chunk, filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/07/2022 03:55:53 PM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/07/2022 03:55:53 PM root translate_file: diff size is 1000 for current chunk, filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/07/2022 03:56:21 PM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/07/2022 03:56:21 PM root translate_file: diff size is 1000 for current chunk, filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/07/2022 03:56:46 PM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/07/2022 03:56:46 PM root translate_file: diff size is 1000 for current chunk, filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/07/2022 03:57:13 PM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/07/2022 03:57:13 PM root translate_file: diff size is 1000 for current chunk, filenames: [data-sets/Lopez1/hydrated/output2020_05.csv data-sets/Lopez1/processed/output2020_05.csv!]\n",
      "🧠INFO    🕑01/07/2022 03:57:41 PM root translate_file:📝appended 1000 rows to data-sets/Lopez1/processed/output2020_05.csv.\n",
      "🧠INFO    🕑01/07/2022 03:57:41 PM root translate_file: limit reached, limit=5000 and count=5000;👋exiting!\n"
     ]
    }
   ],
   "source": [
    "translate_file(\"output2020_05.csv\", limit=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5482fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(processed_path + \"/output2020_05.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "801ff53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234036905316159488</th>\n",
       "      <td>Sun Mar 01 08:45:00 +0000 2020</td>\n",
       "      <td>44% denkt dat de Corona-virus epidemie erger z...</td>\n",
       "      <td>44% think the Corona virus epidemic will get w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234383118334922752</th>\n",
       "      <td>Mon Mar 02 07:40:43 +0000 2020</td>\n",
       "      <td>Gondstofbelasting wordt de norm. Ook voor blon...</td>\n",
       "      <td>Gand dust load is becoming the norm. Also for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234831817817063424</th>\n",
       "      <td>Tue Mar 03 13:23:42 +0000 2020</td>\n",
       "      <td>Aantal met coronavirus besmette personen in Ne...</td>\n",
       "      <td>Number of people infected with coronavirus in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235077563334012928</th>\n",
       "      <td>Wed Mar 04 05:40:12 +0000 2020</td>\n",
       "      <td>Vietnam carrier Vietjet to halt flights to S. ...</td>\n",
       "      <td>Vietnam carrier Vietjet to halt flights to S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235492331970793472</th>\n",
       "      <td>Thu Mar 05 09:08:20 +0000 2020</td>\n",
       "      <td>RT @haP65: @NikaDragomira Fife's idiocy is now...</td>\n",
       "      <td>RT @haP65: @NikaDragomira Fife's idiocy is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236676134680625152</th>\n",
       "      <td>Sun Mar 08 15:32:21 +0000 2020</td>\n",
       "      <td>seokjin paying for yoongis birthday dinner mak...</td>\n",
       "      <td>seokjin paying for yoongis birthday dinner mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236735959175237632</th>\n",
       "      <td>Sun Mar 08 19:30:04 +0000 2020</td>\n",
       "      <td>En als alle IC bedden bezet zijn kan de rest v...</td>\n",
       "      <td>And if all IC beds are occupied, the rest of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236759061544214528</th>\n",
       "      <td>Sun Mar 08 21:01:52 +0000 2020</td>\n",
       "      <td>@FD_Nieuws Hopelijk hebben ze alle panelen al ...</td>\n",
       "      <td>@FD_Nieuws Hopefully they have already purchas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236997826959347712</th>\n",
       "      <td>Mon Mar 09 12:50:38 +0000 2020</td>\n",
       "      <td>Leraar middelbare school besmet. Tien andere l...</td>\n",
       "      <td>High school teacher infected. Ten other teache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237096933950357504</th>\n",
       "      <td>Mon Mar 09 19:24:27 +0000 2020</td>\n",
       "      <td>Voor de niet ingewijden: grafiekjes zijn log-s...</td>\n",
       "      <td>For the uninitiated: graphs are log-scales. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         created_at  \\\n",
       "id                                                    \n",
       "1234036905316159488  Sun Mar 01 08:45:00 +0000 2020   \n",
       "1234383118334922752  Mon Mar 02 07:40:43 +0000 2020   \n",
       "1234831817817063424  Tue Mar 03 13:23:42 +0000 2020   \n",
       "1235077563334012928  Wed Mar 04 05:40:12 +0000 2020   \n",
       "1235492331970793472  Thu Mar 05 09:08:20 +0000 2020   \n",
       "...                                             ...   \n",
       "1236676134680625152  Sun Mar 08 15:32:21 +0000 2020   \n",
       "1236735959175237632  Sun Mar 08 19:30:04 +0000 2020   \n",
       "1236759061544214528  Sun Mar 08 21:01:52 +0000 2020   \n",
       "1236997826959347712  Mon Mar 09 12:50:38 +0000 2020   \n",
       "1237096933950357504  Mon Mar 09 19:24:27 +0000 2020   \n",
       "\n",
       "                                                             full_text  \\\n",
       "id                                                                       \n",
       "1234036905316159488  44% denkt dat de Corona-virus epidemie erger z...   \n",
       "1234383118334922752  Gondstofbelasting wordt de norm. Ook voor blon...   \n",
       "1234831817817063424  Aantal met coronavirus besmette personen in Ne...   \n",
       "1235077563334012928  Vietnam carrier Vietjet to halt flights to S. ...   \n",
       "1235492331970793472  RT @haP65: @NikaDragomira Fife's idiocy is now...   \n",
       "...                                                                ...   \n",
       "1236676134680625152  seokjin paying for yoongis birthday dinner mak...   \n",
       "1236735959175237632  En als alle IC bedden bezet zijn kan de rest v...   \n",
       "1236759061544214528  @FD_Nieuws Hopelijk hebben ze alle panelen al ...   \n",
       "1236997826959347712  Leraar middelbare school besmet. Tien andere l...   \n",
       "1237096933950357504  Voor de niet ingewijden: grafiekjes zijn log-s...   \n",
       "\n",
       "                                                        processed_text  \n",
       "id                                                                      \n",
       "1234036905316159488  44% think the Corona virus epidemic will get w...  \n",
       "1234383118334922752  Gand dust load is becoming the norm. Also for ...  \n",
       "1234831817817063424  Number of people infected with coronavirus in ...  \n",
       "1235077563334012928  Vietnam carrier Vietjet to halt flights to S. ...  \n",
       "1235492331970793472  RT @haP65: @NikaDragomira Fife's idiocy is now...  \n",
       "...                                                                ...  \n",
       "1236676134680625152  seokjin paying for yoongis birthday dinner mak...  \n",
       "1236735959175237632  And if all IC beds are occupied, the rest of t...  \n",
       "1236759061544214528  @FD_Nieuws Hopefully they have already purchas...  \n",
       "1236997826959347712  High school teacher infected. Ten other teache...  \n",
       "1237096933950357504  For the uninitiated: graphs are log-scales. Th...  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(processed_path + \"output2020_05.csv\", \n",
    "                      nrows=400,\n",
    "                      index_col=\"id\",\n",
    "                      usecols=[\"id\", \"full_text\", \"created_at\"])\n",
    "df2 = pd.read_csv(result_filename,  index_col=\"id\",\n",
    "                      usecols=[\"id\", \"full_text\", \"processed_text\", \"created_at\"])\n",
    "\n",
    "df3 = df[~df.index.isin(df2.index)]\n",
    "df3\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "414cbdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [full_text, created_at, processed_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(None, columns=[\"id\", \"full_text\", \"created_at\", \"processed_text\"])\n",
    "df = df.set_index(\"id\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01ed8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(filename, \n",
    "                      nrows=20,\n",
    "                      index_col=\"id\",\n",
    "                      usecols=[\"id\", \"full_text\", \"created_at\"])\n",
    "\n",
    "\n",
    "#pd.Series([df2[\"full_text\"].apply(lambda txt: gtranslate(txt))], index=df2.index, name=\"processed_text\")\n",
    "se = df2[\"full_text\"].apply(lambda txt: gtranslate(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e2dd061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1234036905316159488    44% think the Corona virus epidemic will get w...\n",
       "1234383118334922752    Gand dust load is becoming the norm. Also for ...\n",
       "1234831817817063424    Number of people infected with coronavirus in ...\n",
       "1235077563334012928    Vietnam carrier Vietjet to halt flights to S. ...\n",
       "1235492331970793472    RT @haP65: @NikaDragomira Fife's idiocy is now...\n",
       "1235597189759545344    So the inoculation tactics in the bible belt s...\n",
       "1235690260316794880    And so the LIBERALS, who previously humiliated...\n",
       "1235869971378581504    Corona seems to have two variants https://t.co...\n",
       "1236096698570637312    Happy Netherlands is rising fast! 'NO PANIC' s...\n",
       "1236615839551545344    @Paradisbeer @Rzuid70 Being able to spread a c...\n",
       "1236916084554567680    Today I advised my students to wash hands afte...\n",
       "1237107373245956096    I finally know what I'm suffering from....\\n\\n...\n",
       "1237292284158390272    What is the advice with regard to the 'high-fi...\n",
       "1237790238895988736                                              ok fuck\n",
       "1237813027115859968    All football matches in North Brabant would be...\n",
       "1237832359011024896    Oh God. Someone is snorting behind me on the b...\n",
       "1237978525510090752    A game: do I have the coronavirus or do I just...\n",
       "1238007352940474368    https://t.co/IdJN7qIS9X\\nThis does help, for e...\n",
       "1238378863983505408          Meanwhile in the UK https://t.co/6lLjuNuALD\n",
       "1238587278571732992    Let's talk each other out. @Jinek_RTL Give @th...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5cff2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234036905316159488</th>\n",
       "      <td>Sun Mar 01 08:45:00 +0000 2020</td>\n",
       "      <td>44% denkt dat de Corona-virus epidemie erger z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234383118334922752</th>\n",
       "      <td>Mon Mar 02 07:40:43 +0000 2020</td>\n",
       "      <td>Gondstofbelasting wordt de norm. Ook voor blon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234831817817063424</th>\n",
       "      <td>Tue Mar 03 13:23:42 +0000 2020</td>\n",
       "      <td>Aantal met coronavirus besmette personen in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235077563334012928</th>\n",
       "      <td>Wed Mar 04 05:40:12 +0000 2020</td>\n",
       "      <td>Vietnam carrier Vietjet to halt flights to S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235492331970793472</th>\n",
       "      <td>Thu Mar 05 09:08:20 +0000 2020</td>\n",
       "      <td>RT @haP65: @NikaDragomira Fife's idiocy is now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235597189759545344</th>\n",
       "      <td>Thu Mar 05 16:05:00 +0000 2020</td>\n",
       "      <td>De inentings tactiek in de bijbelbelt werkt du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235690260316794880</th>\n",
       "      <td>Thu Mar 05 22:14:50 +0000 2020</td>\n",
       "      <td>En zo krijgen de LIBERALEN, die voordien CD&amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235869971378581504</th>\n",
       "      <td>Fri Mar 06 10:08:57 +0000 2020</td>\n",
       "      <td>Corona lijkt twee varianten te hebben https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236096698570637312</th>\n",
       "      <td>Sat Mar 07 01:09:53 +0000 2020</td>\n",
       "      <td>Gelukkig Nederland stijgt met stip! ‘NO PANIC’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236615839551545344</th>\n",
       "      <td>Sun Mar 08 11:32:46 +0000 2020</td>\n",
       "      <td>@Paradijsbeer @Rzuid70 Het kunnen verspreiden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236916084554567680</th>\n",
       "      <td>Mon Mar 09 07:25:50 +0000 2020</td>\n",
       "      <td>Vandaag heb ik mijn studenten geadviseerd om n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237107373245956096</th>\n",
       "      <td>Mon Mar 09 20:05:56 +0000 2020</td>\n",
       "      <td>Ik weet eindelijk waar ik aan lijdt....\\n\\nCOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237292284158390272</th>\n",
       "      <td>Tue Mar 10 08:20:42 +0000 2020</td>\n",
       "      <td>Hoe luidt eigenlijk het advies m.b.t. de 'high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237790238895988736</th>\n",
       "      <td>Wed Mar 11 17:19:24 +0000 2020</td>\n",
       "      <td>ta foda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237813027115859968</th>\n",
       "      <td>Wed Mar 11 18:49:57 +0000 2020</td>\n",
       "      <td>Nou zouden komend weekend alle voetbalwedstrij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237832359011024896</th>\n",
       "      <td>Wed Mar 11 20:06:46 +0000 2020</td>\n",
       "      <td>Oh god. Iemand zit te snotteren achter mij op ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237978525510090752</th>\n",
       "      <td>Thu Mar 12 05:47:35 +0000 2020</td>\n",
       "      <td>Een spel: heb ik het coronavirus of ben ik gew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238007352940474368</th>\n",
       "      <td>Thu Mar 12 07:42:08 +0000 2020</td>\n",
       "      <td>https://t.co/IdJN7qIS9X\\nDit helpt wel bijvoor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238378863983505408</th>\n",
       "      <td>Fri Mar 13 08:18:23 +0000 2020</td>\n",
       "      <td>Ondertussen in het VK https://t.co/6lLjuNuALD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238587278571732992</th>\n",
       "      <td>Fri Mar 13 22:06:33 +0000 2020</td>\n",
       "      <td>Laat elkaar eens uitpraten. @Jinek_RTL Geef  @...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         created_at  \\\n",
       "id                                                    \n",
       "1234036905316159488  Sun Mar 01 08:45:00 +0000 2020   \n",
       "1234383118334922752  Mon Mar 02 07:40:43 +0000 2020   \n",
       "1234831817817063424  Tue Mar 03 13:23:42 +0000 2020   \n",
       "1235077563334012928  Wed Mar 04 05:40:12 +0000 2020   \n",
       "1235492331970793472  Thu Mar 05 09:08:20 +0000 2020   \n",
       "1235597189759545344  Thu Mar 05 16:05:00 +0000 2020   \n",
       "1235690260316794880  Thu Mar 05 22:14:50 +0000 2020   \n",
       "1235869971378581504  Fri Mar 06 10:08:57 +0000 2020   \n",
       "1236096698570637312  Sat Mar 07 01:09:53 +0000 2020   \n",
       "1236615839551545344  Sun Mar 08 11:32:46 +0000 2020   \n",
       "1236916084554567680  Mon Mar 09 07:25:50 +0000 2020   \n",
       "1237107373245956096  Mon Mar 09 20:05:56 +0000 2020   \n",
       "1237292284158390272  Tue Mar 10 08:20:42 +0000 2020   \n",
       "1237790238895988736  Wed Mar 11 17:19:24 +0000 2020   \n",
       "1237813027115859968  Wed Mar 11 18:49:57 +0000 2020   \n",
       "1237832359011024896  Wed Mar 11 20:06:46 +0000 2020   \n",
       "1237978525510090752  Thu Mar 12 05:47:35 +0000 2020   \n",
       "1238007352940474368  Thu Mar 12 07:42:08 +0000 2020   \n",
       "1238378863983505408  Fri Mar 13 08:18:23 +0000 2020   \n",
       "1238587278571732992  Fri Mar 13 22:06:33 +0000 2020   \n",
       "\n",
       "                                                             full_text  \n",
       "id                                                                      \n",
       "1234036905316159488  44% denkt dat de Corona-virus epidemie erger z...  \n",
       "1234383118334922752  Gondstofbelasting wordt de norm. Ook voor blon...  \n",
       "1234831817817063424  Aantal met coronavirus besmette personen in Ne...  \n",
       "1235077563334012928  Vietnam carrier Vietjet to halt flights to S. ...  \n",
       "1235492331970793472  RT @haP65: @NikaDragomira Fife's idiocy is now...  \n",
       "1235597189759545344  De inentings tactiek in de bijbelbelt werkt du...  \n",
       "1235690260316794880  En zo krijgen de LIBERALEN, die voordien CD&am...  \n",
       "1235869971378581504  Corona lijkt twee varianten te hebben https://...  \n",
       "1236096698570637312  Gelukkig Nederland stijgt met stip! ‘NO PANIC’...  \n",
       "1236615839551545344  @Paradijsbeer @Rzuid70 Het kunnen verspreiden ...  \n",
       "1236916084554567680  Vandaag heb ik mijn studenten geadviseerd om n...  \n",
       "1237107373245956096  Ik weet eindelijk waar ik aan lijdt....\\n\\nCOR...  \n",
       "1237292284158390272  Hoe luidt eigenlijk het advies m.b.t. de 'high...  \n",
       "1237790238895988736                                            ta foda  \n",
       "1237813027115859968  Nou zouden komend weekend alle voetbalwedstrij...  \n",
       "1237832359011024896  Oh god. Iemand zit te snotteren achter mij op ...  \n",
       "1237978525510090752  Een spel: heb ik het coronavirus of ben ik gew...  \n",
       "1238007352940474368  https://t.co/IdJN7qIS9X\\nDit helpt wel bijvoor...  \n",
       "1238378863983505408      Ondertussen in het VK https://t.co/6lLjuNuALD  \n",
       "1238587278571732992  Laat elkaar eens uitpraten. @Jinek_RTL Geef  @...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
